"""
Script de Procesamiento de PDFs - Chinfield
Convierte fichas t√©cnicas PDF en archivos .txt estructurados para ChromaDB
"""

import os
import re
from pathlib import Path
from typing import Dict, List
import PyPDF2


class ChinfieldPDFProcessor:
    """Procesador de fichas t√©cnicas Chinfield"""
    
    def __init__(self, pdf_dir: str, output_dir: str):
        self.pdf_dir = Path(pdf_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def extract_text_from_pdf(self, pdf_path: Path) -> str:
        """Extraer texto completo de un PDF"""
        try:
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text() + "\n"
                return text
        except Exception as e:
            print(f"  ‚ùå Error leyendo {pdf_path.name}: {e}")
            return ""
    
    def parse_ficha_tecnica(self, text: str, filename: str) -> Dict[str, str]:
        """
        Parsear texto de ficha t√©cnica y extraer campos estructurados
        Versi√≥n mejorada que maneja variaciones de formato
        """
        # Normalizar espacios pero mantener saltos de l√≠nea importantes
        text = re.sub(r'\s+', ' ', text)
        
        # Lista de secciones comunes que pueden terminar un campo
        section_headers = [
            'F√ìRMULA', 'ESPECIE DE DESTINO', 'INDICACIONES', 'PRESENTACI√ìN',
            'POSOLOG√çA', 'DOSIS', 'V√çAS DE ADMINISTRACI√ìN', 'CONTRAINDICACIONES',
            'EFECTOS', 'ADVERTENCIAS', 'CONSERVACI√ìN', 'APARIENCIA',
            'PRECAUCIONES', 'INTERACCIONES', 'TIEMPO DE RETIRO'
        ]
        
        # Crear pattern para cualquier header de secci√≥n
        next_section = '|'.join([f'(?:{h})' for h in section_headers])
        
        # Extraer nombre del producto
        nombre_patterns = [
            r'Nombre del producto:\s*(.+?)(?:F√ìRMULA|Cada|$)',
            r'FICHA T√âCNICA\s+(.+?)(?:F√ìRMULA|Cada|$)',
        ]
        nombre = filename.replace('.pdf', '')
        for pattern in nombre_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                nombre = match.group(1).strip()
                # Limpiar nombre (quitar "Nombre del producto:")
                nombre = re.sub(r'^Nombre del producto:\s*', '', nombre, flags=re.IGNORECASE)
                break
        
        # Extraer f√≥rmula - capturar hasta la siguiente secci√≥n
        formula_match = re.search(
            rf'F√ìRMULA:(.+?)(?:{next_section}|P√°gina|$)', 
            text, re.IGNORECASE | re.DOTALL
        )
        formula = formula_match.group(1).strip() if formula_match else "No especificada"
        
        # Extraer especie de destino
        especie_match = re.search(
            rf'ESPECIE DE DESTINO:(.+?)(?:{next_section}|P√°gina|$)', 
            text, re.IGNORECASE | re.DOTALL
        )
        especie = especie_match.group(1).strip() if especie_match else "No especificada"
        
        # Extraer indicaciones - m√°s flexible
        indicaciones_patterns = [
            rf'INDICACIONES:(.+?)(?:{next_section}|P√°gina|$)',
            rf'I\s*N\s*D\s*I\s*C\s*A\s*C\s*I\s*O\s*N\s*E\s*S:(.+?)(?:{next_section}|P√°gina|$)',
        ]
        indicaciones = "No especificadas"
        for pattern in indicaciones_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                indicaciones = match.group(1).strip()
                break
        
        # Extraer posolog√≠a - m√∫ltiples variantes
        posologia_patterns = [
            rf'POSOLOG√çA.*?:(.+?)(?:{next_section}|P√°gina|$)',
            rf'DOSIS.*?:(.+?)(?:{next_section}|P√°gina|$)',
            rf'POSOLOG√çA Y DOSIS.*?:(.+?)(?:{next_section}|P√°gina|$)',
            rf'V√çAS DE ADMINISTRACI√ìN:(.+?)(?:{next_section}|P√°gina|$)',
        ]
        posologia = "No especificada"
        for pattern in posologia_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                content = match.group(1).strip()
                if len(content) > 10:  # Validar que tenga contenido real
                    posologia = content
                    break
        
        # Extraer contraindicaciones
        contra_match = re.search(
            rf'CONTRAINDICACIONES:(.+?)(?:{next_section}|P√°gina|$)', 
            text, re.IGNORECASE | re.DOTALL
        )
        contraindicaciones = contra_match.group(1).strip() if contra_match else "No especificadas"
        
        # Extraer presentaci√≥n
        presentacion_patterns = [
            rf'PRESENTACI√ìN:(.+?)(?:{next_section}|P√°gina|$)',
            rf'PR\s*E\s*S\s*E\s*N\s*T\s*A\s*C\s*I\s*√ìN:(.+?)(?:{next_section}|P√°gina|$)',
        ]
        presentacion = "No especificada"
        for pattern in presentacion_patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                presentacion = match.group(1).strip()
                break
        
        # Limpiar textos capturados (quitar exceso de espacios, headers residuales)
        def clean_text(t):
            # Quitar m√∫ltiples espacios
            t = re.sub(r'\s+', ' ', t)
            # Quitar referencias a p√°ginas
            t = re.sub(r'P√°gina\s+\d+\s+de\s+\d+', '', t, flags=re.IGNORECASE)
            # Quitar info de contacto repetida
            t = re.sub(r'LABORATORIO DE ESPECIALIDADES VETERINARIAS.+?(?=\w|$)', '', t, flags=re.IGNORECASE | re.DOTALL)
            t = re.sub(r'E-mail:\s*info@chinfield\.com.+?(?=\w|$)', '', t, flags=re.IGNORECASE)
            return t.strip()
        
        return {
            'nombre': clean_text(nombre),
            'formula': clean_text(formula),
            'especie': clean_text(especie),
            'indicaciones': clean_text(indicaciones),
            'posologia': clean_text(posologia),
            'contraindicaciones': clean_text(contraindicaciones),
            'presentacion': clean_text(presentacion)
        }
    
    def generate_txt_file(self, data: Dict[str, str], output_path: Path):
        """Generar archivo .txt estructurado"""
        
        content = f"""PRODUCTO: {data['nombre']}

=== F√ìRMULA ===
{data['formula']}

=== ESPECIE DE DESTINO ===
{data['especie']}

=== INDICACIONES ===
{data['indicaciones']}

=== POSOLOG√çA Y DOSIS ===
{data['posologia']}

=== CONTRAINDICACIONES ===
{data['contraindicaciones']}

=== PRESENTACI√ìN ===
{data['presentacion']}

---
Fuente: Laboratorio Chinfield S.A.
Ficha t√©cnica oficial del producto.
"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content.strip())
    
    def process_all_pdfs(self) -> List[str]:
        """Procesar todos los PDFs en el directorio"""
        
        print(f"üîç Buscando PDFs en: {self.pdf_dir}")
        pdf_files = sorted(self.pdf_dir.glob("*.pdf"))
        
        if not pdf_files:
            print(f"‚ùå No se encontraron PDFs en {self.pdf_dir}")
            return []
        
        print(f"üìÑ Encontrados {len(pdf_files)} PDFs\n")
        
        processed = []
        failed = []
        
        for i, pdf_path in enumerate(pdf_files, 1):
            print(f"[{i}/{len(pdf_files)}] Procesando: {pdf_path.name}")
            
            # Extraer texto
            text = self.extract_text_from_pdf(pdf_path)
            
            if not text or len(text) < 100:
                print(f"  ‚ö†Ô∏è  Texto insuficiente, saltando...")
                failed.append(pdf_path.name)
                continue
            
            # Parsear datos
            data = self.parse_ficha_tecnica(text, pdf_path.stem)
            
            # Generar nombre de archivo .txt limpio
            # Reemplazar espacios y caracteres especiales
            safe_name = re.sub(r'[^\w\s-]', '', data['nombre'])
            safe_name = re.sub(r'[-\s]+', '_', safe_name)
            txt_filename = f"producto_{i:02d}_{safe_name[:50]}.txt"
            
            output_path = self.output_dir / txt_filename
            
            # Guardar archivo
            self.generate_txt_file(data, output_path)
            print(f"  ‚úÖ Generado: {txt_filename}")
            
            processed.append(txt_filename)
        
        # Resumen
        print("\n" + "="*70)
        print(f"‚úÖ PROCESAMIENTO COMPLETADO")
        print("="*70)
        print(f"Total PDFs procesados: {len(processed)}/{len(pdf_files)}")
        print(f"Archivos .txt generados: {len(processed)}")
        print(f"Errores: {len(failed)}")
        
        if failed:
            print(f"\n‚ö†Ô∏è  PDFs con errores:")
            for f in failed:
                print(f"  - {f}")
        
        print(f"\nüìÅ Archivos guardados en: {self.output_dir}")
        
        return processed


def main():
    """Funci√≥n principal"""
    
    print("="*70)
    print("üöÄ PROCESADOR DE PDFs - LABORATORIO CHINFIELD")
    print("="*70)
    print()
    
    # Configuraci√≥n de rutas (desde donde se ejecuta el script)
    BASE_DIR = Path.cwd()  # Directorio actual de ejecuci√≥n
    PDF_DIR = BASE_DIR / "data" / "productos_pdf"
    OUTPUT_DIR = BASE_DIR / "data" / "products"
    
    print(f"üìÇ Directorio PDFs: {PDF_DIR}")
    print(f"üìÇ Directorio output: {OUTPUT_DIR}")
    print()
    
    # Verificar que existe el directorio de PDFs
    if not PDF_DIR.exists():
        print(f"‚ùå ERROR: No existe el directorio {PDF_DIR}")
        print(f"   Crear carpeta y colocar PDFs all√≠")
        return 1
    
    # Procesar
    processor = ChinfieldPDFProcessor(
        pdf_dir=str(PDF_DIR),
        output_dir=str(OUTPUT_DIR)
    )
    
    processed = processor.process_all_pdfs()
    
    if len(processed) > 0:
        print("\n‚úÖ Proceso completado exitosamente")
        print(f"   {len(processed)} productos listos para indexar")
        return 0
    else:
        print("\n‚ùå No se pudo procesar ning√∫n PDF")
        return 1


if __name__ == "__main__":
    exit(main())